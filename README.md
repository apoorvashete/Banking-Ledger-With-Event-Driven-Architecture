# Banking-Ledger-With-Event-Driven-Architecture

## Bootstrap instructions
*To run this server locally, do the following:*

1. Update application.properties or application.yml for your specific database settings.

2. You can run the application using: mvn spring-boot:run

3. Once the server is running, the API can be accessed at:
Base URL: http://localhost:8080

4. All APIs use the 'PUT' method


## Design considerations

a. I decided to build the Simple Bank Ledger System using Spring Boot for the following reasons:
1. Ease of Development and Testing: Spring Boot provides a comprehensive set of tools and features that simplify the development process. It has a minimalistic configuration and helps speed up development with various built-in components.
2. Microservices Architecture: With the rise of microservices, Spring Boot is a natural choice due to its lightweight and modular design. It provides an easy way to build standalone microservices that can be deployed in various environments.
3. Spring Ecosystem Integration: Being part of the Spring ecosystem, Spring Boot integrates seamlessly with Spring's wide array of libraries, which include Spring Data for database operations and Spring Security for securing the application.
4. Scalability and Performance: Spring Boot allows for the creation of scalable applications that can handle high volumes of transactions efficiently. Its embedded server options like Tomcat or Jetty enable quick startup times, ideal for cloud deployments.

b. The event schema is as described:
1. Account Created Event: fields= userId, initialBalance, curreny, timestamp
2. Funds Loaded Event: fields= userId, messageId, amountLoaded, curreny, newBalance, timestamp
3. Transaction Authorized Event: fields= userId, messageId, amountAuthorised, curreny, newBalance, timestamp
4. Transaction Declined Event: fields= userId, messageId, amountAttempted, curreny, reason, currentBalance, timestamp

c. In this case, I have decided to use in-memory event storage for the ease of implementation and demonstration. Account aggregator holds the latest state of the account for a userId (implemnted using Hashmap for efficient retrieval and ease of modifying), it is created if does not already exist and we can persist this account aggregate snapshot periodically after a certain number of events on that account.

d. This banking ledger follows SOLID principles.
Single Responsibility Principle (SRP): The system is designed so that each class has a single responsibility. For instance, The AccountAggregator class is solely responsible for reconstructing and maintaining the state of an account based on the events that it handles. The TransactionService class handles the business logic related to transactions such as loading funds or authorizing transactions. The InMemoryEventStore class manages the storage of events in an in-memory data structure. Each class focuses on its defined role, making the system easier to understand, maintain, and extend.
Dependency Inversion Principle (DIP): High-level modules (like the TransactionService class) do not directly depend on low-level implementations but instead rely on abstractions. The event store and event replayer are injected into the TransactionService class, allowing it to be decoupled from the specific implementations and thus more flexible and testable. By utilizing dependency injection, the implementation details can be switched out easily without modifying the service's core logic. For example, different implementations of the EventStore interface (e.g., InMemoryEventStore) can be provided through dependency injection, which decouples the service layer from the specifics of event storage.

e. DRY Principle: The event sourcing pattern itself helps enforce the DRY principle by ensuring that the state of the accounts is not stored or duplicated in multiple places. Instead, it relies on replaying the event history to reconstruct the current state. This avoids redundant representations of data and keeps the logic centralized in the event replayer and aggregator.

Arictectural Diagram:

![Architectural Diagram](https://github.com/apoorvashete/Banking-Ledger-with-Event-Driven-Architecture/assets/63460316/036afb9b-e8f6-4ee4-8f57-07e9a1e13725)

## Assumptions

a. While designing this service, I have made the assumption that:
If a load request is made to a non-existent account, a new account is created with that specific userId.
If an authorization request is made to a non-existent account, the transaction is declined and is saved as an event with the reason: "Account does not exist".

b. The system assumes that ActiveMQ is used for storing events or snapshots. ActiveMQ provides a robust and scalable message broker platform that ensures reliable delivery and persistence of events. The assumption includes:
Event Publisher: All events generated by the application are published to an ActiveMQ topic or queue.
Event Consumer: The system includes a consumer that listens to the ActiveMQ topic or queue and processes the events to update the system's state.
Durable Subscriptions: Ensuring that events are not lost in case of consumer downtime by leveraging durable subscriptions. Message Persistence: The events stored in ActiveMQ are persistent, meaning they can be replayed if needed to reconstruct the system's state.
Snapshot Mechanism: To optimize performance and reduce the need to replay every event from the beginning, snapshots of the system's state are periodically taken and stored. These snapshots are also sent to ActiveMQ to ensure their availability for recovery and replay.

c. The system assumes that events are stored and processed sequentially to ensure the integrity and consistency of the application state. ActiveMQ provides mechanisms to guarantee message ordering during delivery and consumption to uphold this property. The system relies on the event sourcing pattern, where the state of the system is derived from a sequential log of events. The ordered log of events ensures the reconstruction of the application's state at any point in time.


## Deployment considerations

If I were to deploy this Simple Bank Ledger System application, I would choose a cloud provider like AWS, Azure, or Google Cloud for scalable infrastructure. The application would be packaged using Docker to ensure consistent deployment across environments. I would use Kubernetes for orchestration to facilitate easy scaling, self-healing, and rolling deployments. A continuous integration and delivery (CI/CD) pipeline, such as Jenkins or GitHub Actions, would automate testing and deployment.
To manage traffic and ensure high availability, a load balancer would distribute traffic across multiple instances of the application, with auto-scaling to adjust the number of running instances based on demand.

## Future Scope

1. Leveraging an ActiveMQ to communicate using events between consumers and producers across architectures.
2. Leveraging MySQL/ Relational Database to store events
3. Implement OAuth for API Security: As the system scales and exposes more APIs to third-party applications, robust security measures will be essential to protect sensitive data and transactions. Implementing OAuth (Open Authorization) can provide a standardized, secure, and flexible way to authorize access to the system's APIs.

